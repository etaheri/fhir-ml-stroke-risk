{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train the model\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
      ],
      "metadata": {
        "id": "dylTPG54KWaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmQPUrqOH62k",
        "outputId": "317cc9bd-3639-4370-a0f6-f49f341f3d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best Accuracy Score: 0.9545010818397561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier Model accuracy: 0.9393346379647749\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.94      1.00      0.97       960\n",
            "         1.0       0.00      0.00      0.00        62\n",
            "\n",
            "    accuracy                           0.94      1022\n",
            "   macro avg       0.47      0.50      0.48      1022\n",
            "weighted avg       0.88      0.94      0.91      1022\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stroke_prediction_model_best_rf.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# load the dataset\n",
        "df = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')\n",
        "\n",
        "# convert categorical features to numeric using label encoding\n",
        "le = LabelEncoder()\n",
        "df['gender'] = le.fit_transform(df['gender'])\n",
        "df['ever_married'] = le.fit_transform(df['ever_married'])\n",
        "df['work_type'] = le.fit_transform(df['work_type'])\n",
        "df['Residence_type'] = le.fit_transform(df['Residence_type'])\n",
        "df['smoking_status'] = le.fit_transform(df['smoking_status'])\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "# drop the id column as it's not useful for prediction\n",
        "df.drop('id', axis=1, inplace=True)\n",
        "\n",
        "# split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('stroke', axis=1), df['stroke'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [2, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# train a random forest classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform grid search to find the best hyperparameters\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and the corresponding accuracy score\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy Score:\", grid_search.best_score_)\n",
        "\n",
        "# Fit the model using the best hyperparameters and predict the stroke probability for the test set\n",
        "best_rf = grid_search.best_estimator_\n",
        "best_rf.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model on the test set\n",
        "accuracy = best_rf.score(X_test, y_test)\n",
        "print('RandomForestClassifier Model accuracy:', accuracy)\n",
        "\n",
        "# Predict the stroke classes for the test set\n",
        "y_pred = best_rf.predict(X_test)\n",
        "\n",
        "# Compute and print the precision and recall\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# save the trained model to a file\n",
        "joblib.dump(best_rf, 'stroke_prediction_model_best_rf.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the max probability in the dataset (for use in the score calculation)"
      ],
      "metadata": {
        "id": "eOCyYZPgSuuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict stroke probability for all instances in the dataset\n",
        "probas = best_rf.predict_proba(df.drop('stroke', axis=1))\n",
        "\n",
        "# find the maximum probability and its corresponding index\n",
        "max_proba = np.max(probas[:, 1])\n",
        "max_index = np.argmax(probas[:, 1])\n",
        "\n",
        "print(max_proba, max_index)\n",
        "\n",
        "print(df.loc[max_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYRkaIxwSqn9",
        "outputId": "7d0215f0-f834-4d52-b295-81dbfae3fcfb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7764451659451659 171\n",
            "gender                0.00\n",
            "age                  79.00\n",
            "hypertension          1.00\n",
            "heart_disease         1.00\n",
            "ever_married          0.00\n",
            "work_type             3.00\n",
            "Residence_type        0.00\n",
            "avg_glucose_level    60.94\n",
            "bmi                  28.10\n",
            "smoking_status        2.00\n",
            "stroke                1.00\n",
            "Name: 171, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model"
      ],
      "metadata": {
        "id": "5WEP6TilKaMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "model = joblib.load('stroke_prediction_model_best_rf.joblib')\n",
        "\n",
        "# test input data\n",
        "input_data = {\n",
        "    'gender': 'Male', \n",
        "    'age': 79, \n",
        "    'hypertension': 1, \n",
        "    'heart_disease': 1, \n",
        "    'ever_married': 'No', \n",
        "    'work_type': 'Never_worked', \n",
        "    'Residence_type': 'Urban', \n",
        "    'avg_glucose_level': 60, \n",
        "    'bmi': 28.10,\n",
        "    'smoking_status': 'smokes'\n",
        "    }\n",
        "\n",
        "# input mapping\n",
        "label_encode_dict = {\n",
        "    'gender': {'Male': 0, 'Female': 1, 'Other': 2},\n",
        "    'ever_married': {'No': 0, 'Yes': 1},\n",
        "    'work_type': {'children': 0, 'Govt_job': 1, 'Never_worked': 2, 'Private': 3, 'Self-employed': 4},\n",
        "    'Residence_type': {'Rural': 0, 'Urban': 1},\n",
        "    'smoking_status': {'Unknown': 0, 'never smoked': 1, 'formerly smoked': 2, 'smokes': 3}\n",
        "}\n",
        "\n",
        "# map the inputs\n",
        "for feature in label_encode_dict:\n",
        "    if input_data[feature] in label_encode_dict[feature]:\n",
        "        input_data[feature] = label_encode_dict[feature][input_data[feature]]\n",
        "    else:\n",
        "        input_data[feature] = np.nan\n",
        "\n",
        "input_values = np.array([input_data['gender'], input_data['age'], input_data['hypertension'], input_data['heart_disease'],\n",
        "                        input_data['ever_married'], input_data['work_type'], input_data['Residence_type'],\n",
        "                        input_data['avg_glucose_level'], input_data['bmi'], input_data['smoking_status']])\n",
        "    \n",
        "# make the prediction using the loaded model\n",
        "prediction = model.predict_proba([input_values])[0][1]\n",
        "# prediction_other = model.predict([input_values])[0]\n",
        "\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0REuUlmI8yn",
        "outputId": "0dc08131-9cb5-4734-fe58-819bb0b02b4f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5680033930857874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure out how to generate a score out of 100"
      ],
      "metadata": {
        "id": "Lg5XtTsAsauK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prob_to_risk_one(probability):\n",
        "    odds = probability / (1 - probability)\n",
        "    risk = 50 * (1 + np.log(odds))\n",
        "    return risk\n",
        "\n",
        "print(prob_to_risk_one(prediction))\n",
        "\n",
        "def prob_to_risk_two(probability, max_probability):\n",
        "    risk = probability * 100 / max_probability\n",
        "    return risk\n",
        "\n",
        "print(prob_to_risk_two(prediction, max_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2wU7OtDKwln",
        "outputId": "598e86bb-3fd3-4856-b6a1-dc1d0f010c93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63.6854829298938\n",
            "73.1543472737521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0k7VQ0aWQ7PR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}